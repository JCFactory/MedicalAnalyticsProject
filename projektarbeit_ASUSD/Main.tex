\input{preamble}
\input{Abkuerzung}

\begin{document}
\input{Titelseite}

\chapter{Abstract}\label{abstract}
\ref{abstract}

\chapter{Introduction}\label{introduction}

\chapter{Related work}\label{related}

Zhao et al. \footnote{\autocite{zhao_2016}} describe how topic modeling can be used to analyze \gls{ngs}. By implementing topic modelling, text corpus are generated \autocite{zhao_2016}.

In the beginning of every genome analysis, there are several important questions to ask. Jurca et al. \autocite{jurca_2016} recommend to ask the following questions: What are the top studied genes in breast cancer? How regulated blood cancer research is in each country? Which countries have studied the largest number of breast cancer? Which are the popular genes mentioned together by countries every year? Where do key genes lie in the soft clusters?

Jurca et al. describe a process to use large-scale text analysis of biomedical abstracts in order to generate new hypothesis about cancer biomarkers \autocite{jurca_2016}. The target is to develop a data minng methodology that patterns in genes associated with cancer. By analyzing disease-specific gene expression data, experimental data is being checked whether a gene has indeed been upregulated or downregulated with respect to a disease.

According to Xu et al. \autocite{xu_2013}, \gls{mirna}s build a class of 17-27 nucleotides single-stranded \gls{rna} molecules that regulate gen expression post-transcriptionally. In the described text-mining process, Xu et al. identified nine \gls{mirna}s in bladder cancer and adopted protein-protein interaction sites between these miRNAs and target genes. The results of the analyzation process lead to two relationship types between bladder cancer and its \gls{mirna}: casual and unspecified. 

Topic modelling is not only used to analyze relationships between genomes but also to improve diagnoses for stroke disease. Djatna et al. \autocite{djatna_2018} describe an 'Intuitionistic Fuzzy Based Decision Tree' to diagnose different types of stroke disease. To be precise, the different types of stroke diseases can be calculated by Hamming distance. The term 'Fuzzy logic' means logic that underlies the reasoning of data by way of precise estimates. It is the fastest way to map input space into output space using a degree of membership.

Lloret et al. \footnote{\autocite{lloret_2012}} built an automatic summarization algorithm for literature. It can includes three steps: First, topic identification, second topic interpretation and third summary generation. While describing the process of textual analyzation, Lloret et al. mention a specific term: \gls{tfidf} which is important for topic modelling. In addition to topic-based approaches, there are graph-based approaches and discourse-based approaches. Graph-based approaches implicate nodes that represent text elements and the edges/links refer to synonymy \autocite{lloret_2012}. Discourse-based approaches include \gls{rst}, \gls{hmm}, \gls{rst} or \gls{bm}. 

Yang et al. \autocite{yang_2018} describe a process of 'constructing a database for relations between human \gls{cnv}s and human genetic disease via systematic text mining'. In general, \gls{cnv} can cause disease by gene dosage, disruption, fusion or other genetic position effects. 
To be more precise, there can \gls{cnv} can lead to two types of autosomal variants: They can either cause deletion or amplification of the long or broken arm region of chromosomes 1-22 or can build multiples of chromosomes 1-21 (e.g. as in disease trisomy 21). 

According to their article, Yang et al. used \gls{cnv} database which linked the \gls{cnv} information to the \gls{ncbi} Gene and Ontology database. In their article, Yang et al.\autocite{yang_2018} mention three steps in the text mining process. First, during the pre-processing step, unstructured fields are split into separated sentences by using \gls{nltk}, a python package \autocite{nltk}. After that, in the \gls{ner} step, all disease mentions within DNorm system, such as MeSH IDs are recognized. In the third step, \gls{re}, the positions in sentences and entities are compared to generate instances that constist of two candidate entities within one single sentence.

Yang et al. mention two more processing methods: Parallel Processing and Post Processing which includes data cleaning and statistics \autocite{yang_2018}. The term 'data cleaning' is explained as 'de-duplicating data after each step of the process to reduce repetitive operations and prevent statistical errors'. This is a very useful step in biomedicine since as a common problem, biomedical databases contain errors. For that reason, users can give feedback through a feedback mechanism to improve the quality of the databases.
 
\chapter{\gls{lda}}\label{lda}
\section{General description}\label{lda_description}
According to Jurca et al. \autocite{jurca_2016} the text mining process can be divided into four steps: First, the information has to be retrieved by user queries (\gls{ir}). Second, different vocabularies and ontologies have to be integrated (\gls{ner}). Third, during \gls{ie}, relationships between biological entities in the texts are extracted by either use co-occurence processing or \gls{nlp}. Last, there has to be gained biologically meaningful knowledge about how biological entities are related by using \gls{kd} methods.

Moreover, there can be distinguished between three types of clustering: hard clustering, hierarchical clustering and soft clusternig. Hard clustering describes the process of separating items into distinct groups where each item is exactly in one cluster. Hierarchical clustering implicates single-link (how similar the items are to one another) and complete-link (how dissimilar the items are). Soft clustering means that items cannot be distinctly separated into clusters and partly are member of two or more clusters at a time \autocite{jurca_2016}.  

Besides, Djatna et al. \autocite{djatna_2018} mention data mining techniques, such as \gls{cart}, \gls{idb}, \gls{dt} and two classification techniques: \gls{pca} and \gls{lda}. 

\gls{lda} was developed by David Blei et. al in the year 2003 and is a clustering algorithm for text mining. It counts to the most popular topic modelling algorithms \autocite{zhao_2016}.
According to \autocite{zhao_2016}, topic modelling requires of a number documents which represent each of them a mixture of latent topics. Moreover, each topic is expressed by a distribution of words. During \gls{lda}, two relationships are analyzed: First, the relationship between documents and words, also called 'per-document topic distributions'. Second, the relationship between words and topics ('per-topic word distributions'). To measure the relationships exactly and to make inference about topics and documents for text mining, probability matrices are calculated.
 
\section{Examples and possible use cases}\label{lda_examples}

Zhao et al. describe the process of analyzing genomes as follows: First, each document corresponds to one of the total number of \gls{dna} straints. Second, all documents had the same number of words. Third, the distribution of words for topics as well as the distribution of topics in documents were described by random variables obeying Dirichlet distributions with parameters $\alpha$ and $\beta$. After that, nucleotides and their orders in \gls{ngs} sequences coudl be treated as words and the genetic information in sequences was translated and exhibited as a 'bag of words'  \autocite{zhao_2016}. By using the strain-topic matrix derived from topic modelling, relationships or similarities between the strains serotypes can be found out. 
 
images and schemes
\section{Python package 'Gensim'}\label{gensim}
              
\chapter{Acute Lymphoblastic Leukemia}\label{all}
\section{Types of Leukemia and its causes}\label{leukemia_types}
According to Jurca et al. \autocite{jurca_2016}, cancer is the result of damage, especially of mutations to cell's \gls{dna} which leads to a cell losing its normal functionality and gains the ability to indefinitely multiply until normal tissue funtions are impaired. This is also why malitious cancer is distributing so fast. Besides, each patient develops a different set of cancerous mutations in various genes which lead to multiple subtypes of cancer.
Furthermore, some genes can be up-regulated (which means that they are transcribed more and are expressed), down-regulated (which means that they are not expressed) or can be co-expressed (which means that they are expressed at the same time \autocite{jurca_2016}.

As stated by Montano et al. \autocite{montano_2018}, \gls{all} is a malignant disorder originating from hematopoietic B-/T-cell precursors which are characterized by marked heterogenity at molecular and clinical levels. There are many approaches to analyze these precursors, such as analyzing targeting of transcriptional factors (PAX5) which are involved in the pathogenesis of B-ALL. Other therapeutic and clinical approaches are genome editing techniques, i.e. the design of new therapies (\gls{car}s) and the study of genes involved in the evolution of pathogenesis.

\section{Examples for Genome Analysis: \gls{ngs}}\label{genome_analysis}
\gls{ngs} refers to post-Sanger sequencing methods \autocite{zhao_2016}. Since \gls{ngs} produces large volumes of sequence data it might be very useful to use topic modelling techniques to maintain the flexibility for the level of resolution required for given experiments.  
According to Gasperskaja et al. \autocite{gasperskaja_2017}, \gls{ngs} does not require a priori knowledge about genomic feature, it only requires a low amount of \gls{dna} or \gls{rna} as input.

The step before analyzing two or more (multiple) genomes is called alignment which includes a comparison of two genomes. There are many different types of alignments, but Zhao et al. refer to the \gls{msa} by describing \gls{muscle} and CLUSTAL.

Gasperskaja et al. \autocite{gasperskaja_2017} mention an important question which should be asked before every genome analysis: 'Is the variance pathogenic?' and whether there is any relationship between genotype and phenotype which means that it can lead to disease or can cause a number of disorders. 
Furthermore, Gasperskaja et al. \autocite{gasperskaja_2017} describe \gls{crispr-cas9} as an example for systems to explain functions of genes and proteins or research relationship between genotype and phenotype. Moreover, there can be distinguished between beneficial (\gls{snp}) and pathogenic (nonsense variant) single nucleotide changes, large microscopically visible or chromosomal aberation. 
To find out whether a genome mutation is pathogenic, Gasperskaja et al. \autocite{gasperskaja_2017} explain that substantial information about functional genomics can be found through analysis of \gls{mrna} or \gls{crna} (which is a copy from \gls{mrna} by reverse transcription \gls{pcr}.
Methods to measure \gls{rna} expression are for example: \gls{sage} or \gls{qpcr}.
By using \gls{cdna} microarray assays important genome-wide information about changes of gene expression in various cell lines can be found out.


\section{Data sources: \gls{ncbi} and Ensembl genome browser 96}\label{datasources}

\chapter{Development of a solution for genetic analysis of \gls{all} genomes by implementing \gls{lda}}\label{development}
\section{Problems and challenges of genetic analysis}\label{problems_challenges}
\section{First steps: Draft of developed solution}\label{draft}

To get useful data, the \autocite{ncbi} was used to get all currently detected mutations of genomes which may cause \gls{lda}.

The first idea was to build a parsing application, which iterates over the found 582 genomes. After the iteration, it compares the oncogenes with the healthy genomes and to figure out where the differences are. The results might be displayed in a diagram. It might be possible to create clusters from the differences between the two groups or practice \gls{lda} on the differences.

\section{Proposed solution}\label{proposed_solution}
\section{Results}\label{results}

\chapter{Conclusion and Outlook}\label{conclusion_outlook}
\section{Lessons learned}\label{lessons_learned}
\section{Conclusion}\label{conclusion}
\section{Outlook}\label{outlook}	
	
% Beispiel f√ºr Bild
		\begin{figure}[htbp]
			\centering
			%\includegraphics[width=1\textwidth]{Image/xxx.pdf}
			\caption[xxx]{Bildunterschrift}
			\label{xxx}
		\end{figure}
		
		
% Beispiel Zitat		
		\begin{quote}
			\textit{Ein Zitat}
		\end{quote}


% Quellenangabe 		\autocite[Seite]{Autor.Jahr}
				\autocite[20]{}

\input{Verzeichnis}
\newpage

\input{Anhang}
\bibdata{Lit}



\end{document}
